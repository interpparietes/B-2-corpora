{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "УДАЛЕНИЕ ПУНКТУАЦИИ, ТОКЕНИЗАЦИЯ, ЧАСТОТНОСТЬ СЛОВ"
      ],
      "metadata": {
        "id": "oDOW1W2n5QdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "slyYm18_7jvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "6s49pkgP9Z1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/B-2-corpora.txt', 'r', encoding = 'utf8') as file:\n",
        "  data = file.read().replace('\\n', ' ')"
      ],
      "metadata": {
        "id": "nQn-fjeN9cpY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.lower()\n",
        "spec_chars = string.punctuation + \"«»\\t—…’\"\n",
        "data = \"\".join([ch for ch in data if ch not in spec_chars])"
      ],
      "metadata": {
        "id": "a3vrt_OkBRQD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_tokens = word_tokenize(data)\n",
        "text_tokens\n",
        "text_data = nltk.Text(text_tokens)"
      ],
      "metadata": {
        "id": "dSFlXOzC-S9r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "russian_stopwords = stopwords.words(\"russian\")"
      ],
      "metadata": {
        "id": "gOJSG_ok7ozK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = [token.lower().strip() for token in text_data if token not in russian_stopwords]\n",
        "text = nltk.Text(text_data)"
      ],
      "metadata": {
        "id": "2hK1jiRR_TM_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist"
      ],
      "metadata": {
        "id": "uW6Q8zPV-iUQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fdist = FreqDist(text)\n",
        "fdist.most_common(14)"
      ],
      "metadata": {
        "id": "Uo91h5uT_Ozr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "СЧИТАЕМ КОСИНУСНОЕ СХОДСТВО"
      ],
      "metadata": {
        "id": "oBAcP11ZFXcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "RZxSO-TkFMM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "rGS_wyGgFJ0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "Uce6AzKpFvbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [data1998, data2000, data2001, data2004, data2006, data2009, data2010, data2011, data2014, data2017, data2022]\n",
        "\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings.shape)\n",
        "\n",
        "similarities = model.similarity(embeddings, embeddings)\n",
        "print(similarities)\n",
        "\n",
        "similarity_list = []\n",
        "for my_list in similarities:\n",
        "  for num in my_list:\n",
        "      similarity_list.append(float(num))\n",
        "\n",
        "print(sum(similarity_list)/len(similarity_list))"
      ],
      "metadata": {
        "id": "t3sagyZ0Fytp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}